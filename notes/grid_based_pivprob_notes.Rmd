---
title: "Grid-based pivot probabilities"
author: "Andy Eggers"
date: "13 August 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

One approach to computing pivot probabilities, given a belief distribution for which we can compute densities, is grid-based numerical integration. Specifically, we 

1. define a grid of points that satisfy the conditions of the pivot probabilities, 
2. compute the density at each point,
3. sum up the densities and normalize using the volume surrounding each grid point. 

This note is to explain the work I've done on this, including checks on whether it is working. 

## Plurality 

I don't think I really need grid-based methods for plurality, because the analytical solution we have already is fast and accurate. But working through the issues might help determine what problems we face in the harder cases. It is also possible that the grid-based approach yields better answers because, unlike the analytical approach in Eggers & Vivyan, it doesn't make the independence assumption about lower-finishing candidates. 

For three candidates, the tie grid for $a$ and $b$ is the line where $a$ and $b$ receive the same vote share between 1/3 and 1/2; for four candidates it is the plane where $a$ and $b$ receive the same vote share between 1/4 and 1/2 and $c$ and $d$ receive lower vote shares. 

We can define a grid for $k$ candidates in the method `plurality_tie_grid()` by specifying all combinations vote shares for $k-2$ candidates, then requiring that the $k-1$th candidate has the same share as the first, and then specifying the $k$th candidate to have 1 minus the sum of the other candidates' shares. Then we prune such that 

- the 1st has the highest vote share
- the $k$th candidate's share is positive (actually, greater than the minimum of all other shares, i.e. the first increment in the grid).

Let's show how this works. We will show: 

- that the grid-based approach gets closer and closer to a large (slow) direct Monte Carlo draw as the grid gets finer and finer
- that the RMSE of the grid-based answer gets closer and closer to the Monte Carlo draw as the size of the Monte Carlo draw gets bigger (and we will compare this convergence to the convergence of the analytical solution).

I have found in doing analysis that the grid-based approach goes astray when any of the alpha components is very small. One way to address this is to just boost the very small alpha components. Another way is to focus attention on cases where none of the alpha components is very small. For this test I will add $\text{Dir}(1, 1, \ldots, 1)$ to the $\alpha$ vector we draw, so that none of the components will be very small. This could be justified as a prior. 

Here is the simulation: 

```{r load_stuff, message = F}
source("R/grid_based_pivot_probs.R")
source("R/plurality_pivprobs.R")
library(tidyverse)
```

```{r plurality_grid_simulation, cache = T, message = F}
# ultimately these will be part of the package

# we want to: 
# draw an alpha_vec 
# compute sim-based results (3?)
# get grid based results (3?)
# get analytical results 

Ns <- c(10000, 100000, 1000000, 10000000)

set.seed(123)
J <- 100

v_mat <- gtools::rdirichlet(J, alpha = c(5, 4, 3, 2))
ss <- runif(J, min = 10, max = 50)

gb_store <- list()
a_store <- list()
sim_store <- list()

for(j in 1:J){

  cat(j, ": ", sep = "")
  v_vec <- as.numeric(v_mat[j,])
  s <- ss[j]
  alpha_vec <- rep(1, length(v_vec)) + v_vec*s

  # simulation-based answers
  cat(" s ")
  df <- tibble(N = Ns)
  df %>%
    mutate(sim_result = pmap(., plurality_pivot_probs_simulation_based, alpha = alpha_vec)) %>% 
    unnest_longer(col = sim_result, values_to = "value", indices_to = "pp")  %>% 
    mutate(j = j) -> sim_results

  sim_store[[j]] <- sim_results 
  
  # grid-based results
  cat(" g ")
  df <- tibble(increment = (1:5)/100) %>%
    mutate(gb_result = pmap(., plurality_pivot_probs_grid_based, alpha_vec = alpha_vec, cand_names = letters[1:length(alpha_vec)])) %>%
    unnest_longer(col = gb_result, values_to = "value", indices_to = "pp")  %>% 
    mutate(j = j) -> gb_results
  
  gb_store[[j]] <- gb_results

  # analytical results
  cat(" a.\n")
  alpha.vec <- alpha_vec
  names(alpha.vec) <- letters[1:length(alpha.vec)]
  dfa <- tibble(n = 1) %>%
    mutate(a_result = pmap(., pivotal.probabilities.analytical, alpha.vec = alpha.vec)) %>%
    unnest_longer(col = a_result, values_to = "value", indices_to = "pp")  %>% 
    mutate(j = j) -> a_results
  
  a_store[[j]] <- a_results

}

```

First we prep the data: 


```{r rmse_and_grid_size, cache = T}

big_sim <- bind_rows(sim_store) %>% filter(N == 10000000)

bind_rows(gb_store) %>% 
  left_join(big_sim %>% select(-N), by = c("pp", "j"), suffix = c("_grid", "_sim")) -> for_rmses

for_rmses %>%
    group_by(increment, j) %>%
    summarize(rmse = sqrt(sum((value_grid - value_sim)^2)/n()),
              rmse_norm = sqrt(sum((value_grid/sum(value_grid) - value_sim/sum(value_sim))^2)/n())) -> the_rmses
```

Now we show that the grid-based approach tends to get closer to the result of a large, slow direct Monte Carlo simulation as the grid step-size gets smaller: 

```{r plot_rmse_lines_grid_size, cache = T}
# changed? 
the_rmses %>% 
  ggplot(aes(x = factor(increment, levels = c(.05, .04, .03, .02, .01)), y = rmse, group = j)) +
  geom_line(alpha = .5) + 
  scale_y_log10() + 
  geom_line(data = the_rmses %>% group_by(increment) %>% summarize(rmse = mean(rmse)), aes(x = factor(increment, levels = c(.05, .04, .03, .02, .01)), y = rmse), col = "blue", lwd = 1) + 
  labs(x = "Grid step size (increment)", y = "RMSE between grid-based result and\nlarge (10M) direct Monte Carlo result (log scale)")
  
```

Another way of looking at the same data: 

```{r plot_rmse_violins_grid_size, cache = T}
# changed? 
the_rmses %>% 
  ggplot(aes(x = factor(increment, levels = c(.05, .04, .03, .02, .01)), y = rmse)) +
  geom_violin() + 
  scale_y_log10() + 
  labs(x = "Grid step size (increment)", y = "RMSE between grid-based result and\nlarge (10M) direct Monte Carlo result (log scale)")
  
```

It's odd that the RMSE appears to be higher in many cases at an increment of .04 than at .05, and indeed that the average RMSE appears to be highest at .03. I believe this is because the shape of the mesh changes slightly when we change the increment (the mesh gets closer to the edge, and for edges that are diagonal to the main mesh the shape of the jagged edge changes) and sometimes this change in shape will make things worse even as it should estimate the density at the interior better. In my earlier investigations this was particularly an issue when alpha components are small, because then we are getting a lot of error near the edge of the grid, so changes in shape there make a big difference. But I'm surprised to see this here because we don't have very small values of alpha in this simulation. I suspect there is something to learn by looking at these cases: do they have different `v_vec` patterns? 

```{r investigate_weird_cases, cache = T}

# changed? 
the_rmses %>% 
  select(-rmse_norm) %>% 
  pivot_wider(id_cols = c(j), names_from = increment, values_from = rmse, names_prefix = "rmse_") -> rg_wide 

rg_wide %>% 
  filter(rmse_0.05/rmse_0.03 < .5) %>% 
  pull(j) ->
  bad_js

rg_wide %>% 
  filter(rmse_0.05/rmse_0.03 > 1.75) %>% 
  pull(j) ->
  good_js

alpha_mat <- v_mat*ss + matrix(1, nrow = nrow(v_mat), ncol = ncol(v_mat))
alpha_mat[bad_js,]
alpha_mat[good_js,]
```

I don't see much pattern there. It's a mystery. 

Next we show that the grid-based approach with a small increment tends to get closer to the direct Monte Carlo result as the size of the Monte Carlo simulation gets bigger: 

```{r rmse_and_mc_size, cache = T}

# changed?
bind_rows(gb_store) %>% 
  mutate(type = "grid") %>% 
  filter(increment == .01) %>% 
  select(-increment) %>% 
  bind_rows(
    bind_rows(a_store) %>% 
      mutate(type = "analytical") %>% 
      select(-n)) %>%
  right_join(bind_rows(sim_store), by = c("pp", "j"), suffix = c("", "_sim")) -> for_rmses

for_rmses %>%
    group_by(type, j, N) %>%
    summarize(rmse = sqrt(sum((value - value_sim)^2)/n()),
              rmse_norm = sqrt(sum((value/sum(value) - value_sim/sum(value_sim))^2)/n())) -> the_rmses

```

```{r plot_rmse_lines_mc_size, cache = T}

the_rmses %>% group_by(N, type) %>% summarize(rmse = mean(rmse)) -> means_by_N_and_type 

means_by_N_and_type

# changed? 
the_rmses %>% 
  ggplot(aes(x = factor(N), y = rmse, group = j)) +
  geom_line(alpha = .25) + 
  scale_y_log10() + 
  geom_line(data = means_by_N_and_type, aes(x = factor(N), y = rmse, group = type), col = "blue", lwd = 1) + 
  facet_wrap(. ~ type) + 
  labs(x = "Size of direct Monte Carlo simulation", y = "RMSE compared to Monte Carlo result (log scale)")
  
```

The same thing on the linear scale: 


```{r plot_rmse_lines_mc_size_2, cache = T}

# changed 
the_rmses %>% 
  ggplot(aes(x = factor(N), y = rmse, group = j)) +
  geom_line(alpha = .25) + 
  geom_line(data = means_by_N_and_type, aes(x = factor(N), y = rmse, group = type), col = "blue", lwd = 1) + 
  facet_wrap(. ~ type) + 
  labs(x = "Size of direct Monte Carlo simulation", y = "RMSE compared to Monte Carlo result")
  
```

I thought something might be wrong with my approach to plotting means as they look identical, but in fact they are nearly identical:

```{r look_at_means_by_N_and_type}
means_by_N_and_type %>% pivot_wider(names_from = type, values_from = rmse)
```

This suggests that, at least when we get to a grid increment of .01, the error might be due to remaining random variation in the Monte Carlo. 


## Positional methods 

I can continue this about positional methods (e.g. Borda count), where I have encountered more problems. 
