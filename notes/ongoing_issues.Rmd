---
title: "Open questions and next steps"
author: "Andy Eggers"
date: "9/4/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
devtools::load_all()
# source("R/positional_utils.R") # for ordered ballot vector thing
# source("R/simplicial_cubature_utils.R") # for S creation
```

## Errors from Qhull in positional methods 

When I try to compute probabilities for a positional race with 4 candidates, I get a big long error referred to as the `dupridge` error in the qhull documentation. This is very annoying because it's possible that I have set up an elegant and flexible way to compute pivot probabilities for $k$-candidate positional elections but because of problems with software beyond my control I cannot go beyond the simplest case.  

```
>   out3 <- positional_event_probabilities(alpha = sample(2:7, size = 24, replace = T), skip_non_pivot_events = T, merge_adjacent_pivot_events = T, tol = .1)
Error in geometry::delaunayn(all_vertices[, -ncol(all_vertices)]) :
  Received error code 5 from qhull. Qhull error:
QH6271 qhull precision error (qh_check_dupridge): wide merge (130 times wider) due to duplicate ridge with nearly coincident points (0.00056) between f60215 and f60206, merge dist 1.3e-10, while processing p366
- Ignore error with option 'Q12'
- To be fixed in a later version of Qhull
- A bounding box for the input sites may alleviate this error.
- Vertex distance 0.00056 is greater than 100 times maximum distance 1e-12
  Please report to bradb@shore.net with steps to reproduce and all output
ERRONEOUS FACET:
- f60215
    - flags: bottom upperDelaunay new seen mergehorizon dupridge mergeridge2
    - normal:    0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085 3.032e-13
    - offset: -0.2085144
    - vertices: p366(v32) p430(v31) p1271(v29) p2282(v28) p1849(v27) p3664(v26) p3866
In addition: Warning messages:
1: In positional_event_probabilities(alpha = sample(2:7, size = 24,  :
  No score_vector supplied. Assuming Borda count with 4 candidates.
2: In geometry::delaunayn(all_vertices[, -ncol(all_vertices)]) :

 Error in geometry::delaunayn(all_vertices[, -ncol(all_vertices)]) :
  Received error code 5 from qhull. Qhull error:
QH6271 qhull precision error (qh_check_dupridge): wide merge (130 times wider) due to duplicate ridge with nearly coincident points (0.00056) between f60215 and f60206, merge dist 1.3e-10, while processing p366
- Ignore error with option 'Q12'
- To be fixed in a later version of Qhull
- A bounding box for the input sites may alleviate this error.
- Vertex distance 0.00056 is greater than 100 times maximum distance 1e-12
  Please report to bradb@shore.net with steps to reproduce and all output
ERRONEOUS FACET:
- f60215
    - flags: bottom upperDelaunay new seen mergehorizon dupridge mergeridge2
    - normal:    0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085 3.032e-13
    - offset: -0.2085144
    - vertices: p366(v32) p430(v31) p1271(v29) p2282(v28) p1849(v27) p3664(v26) p3866 
```

I added the `Q12` option to `geometry::delaunayn()` and `geometry::convhulln()` and ran it again. It seemed to hang.

The documentation on Qhull is at http://www.qhull.org/html/qh-impre.htm. 

It looks I could pursue this by 

- switching away from Qhull
- waiting until `geometry` updates to `Qhull2019` and trying experimental option `Q14`
- trying to reproduce the error on a finer grain and seeing if there is something I can do to anticipate and avoid it

For now I am just restricting positional methods to 3 candidates.

And I think I will restrict Kemeny to 3 candidates.  

## Correction for dropping a dimension in positional methods 

I initially got different results when I drop a dimension and do not drop a dimension in positional methods. In the three-candidate case (the only one I've been able to handle so far), I got the same result in plurality and positional with `score_vector` `c(1,0,0)` when I do not drop a dimension. Dropping a dimension gave me pivot probabilities a factor of $\sqrt{2}$ higher. I confirmed in further tests (in `positional_utils.R`) that the factor varies across levels of `s`. I determined what the function seemed to be and have applied this. I now have approximately the same answers from dropping a dimension and not dropping a dimension. If this correction is correct, then I suspect it's correct even as we go to higher-order pivot events, but it won't work for more candidates, as the scoring system can no longer be characterized in terms of a single parameter `s`. But I don't understand why this is the correct scaling, and if I did understand it I could maybe do the extension to more candidates. 

## Things to do 

Extra methods: 

- Kemeny for three candidates 
    - for each candidate, enumerate the decisive condorcet-winner events:
        - $a_$: $a$ ahead of $b$, $a$ ahead of $c$ 
        - $a_b$: set $b$ ahead of $c$ and set $a$ ahead of $c$; $a$ just ahead of $b$
        - $a_c$: set $c$ ahead of $b$ and set $a$ ahead of $b$; $a$ just ahead of $c$
    - for each candidate, enumerate decisive cyclic events:
        - $a_F$: set $a$ ahead of $b$, $b$ ahead of $c$, $c$ ahead of $a$, but $a$'s loss to $c$ better than $b$'s loss to $a$
        - $a_bC$: set $a$ ahead of $b$, $b$ ahead of $c$, $c$ ahead of $a$, but $a$'s loss to $c$ barely better than $b$'s loss to $a$
        - $a_R$: set $b$ ahead of $a$, $c$ ahead of $b$, $a$ ahead of $c$, but $a$'s loss to $b$ better than $c$'s loss to $a$
        - $a_cC$: set $b$ ahead of $a$, $c$ ahead of $b$, $a$ ahead of $c$, but $a$'s loss to $b$ barely better than $c$'s loss to $a$
    - will need to work out P mat for each of these.
- IRV for three candidates
- Eggers Vivyan with extra pivot events -- alter the limits of integration, or just assume we merge adjacent pivot events? 
- Eggers Nowacki for three candidates 
- Monte Carlo: how general? 

I need to clean up and document code. I have tests in the code, etc. 

Then set up and write up results. 

Should I take a break from this? It's driving me nuts. Very exhausting, and honestly I'm not close to done. Other things sliding past that I could finish. 


## Cleaning up and generalizing code

I have undertaken a new approach that I think is really promising. Each event is a set of conditions, a vector of rows to alter, and a $P$ matrix at those conditions. Then we cycle through permutations of the candidates and compute each pivot event for each permutation. (The cycling works differently when it comes to parameters depending on whether it is a single-ballot or ordinal system.) 

Done: 
- define adjacent events in the spec and update code to do this: if we are merging adjacent pivot events, and if this one has one specified, then substitute ijk in the same way, check if that one is already stored, and if so take it out, stick it in, move on. 
- write a function to make plurality events given n and k


To do on this: 

- seems like they're not merging -- diagnose and fix.
- add simulation method, also based on conditions 
- check if the answers are correct 
- check also that, when integral should be higher this side of the boundary, we get about the same result for merge_adjacent_pivot_events whether or not we drop_dimension, and the one on this side of the boundary is higher when we do not  merge_adjacent_pivot_events
- make the scaling factor 1 by default, and only specify it otherwise
- make IRV function that takes n and s, with the first round being any positional method 
- decide how to store the events as part of the package -- that's data. 
- add Kemeny
- for each method, check the results with and without drop_dimension. this will help me pick a scaling factor. (see positional_utils.R code for this.)

Here's some testing of it:

```{r get_events}
el <- plurality_event_list(n = 1000, k = 4)
irv_events <- irv_event_list(n = 1000)
borda_events <- positional_event_list(n = 1000)

alpha6 <- c(6,4, 3,4, 2,6)
alpha4 <- c(10, 9, 6, 4)
```

```{r try_it_basic, cache = T}
# chang
irv_out <- event_probabilities_from_event_list(event_list = irv_events, alpha = alpha6, cand_names = c("a", "b", "c"))

plurality_out <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F)

borda_out <- event_probabilities_from_event_list(event_list = borda_events, alpha = alpha6, cand_names = c("a", "b", "c"), ordinal = T)
```


```{r try_it_skip, cache = T}
# chang
irv_out_s <- event_probabilities_from_event_list(event_list = irv_events, alpha = alpha6, cand_names = c("a", "b", "c"), skip_non_pivot_events = T)

plurality_out_s <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F, skip_non_pivot_events = T)

borda_out_s <- event_probabilities_from_event_list(event_list = borda_events, alpha = alpha6, cand_names = c("a", "b", "c"), ordinal = T, skip_non_pivot_events = T)
```

```{r try_it_skip_merge, cache = T}
# change it 
irv_out_sm <- event_probabilities_from_event_list(event_list = irv_events, alpha = alpha6, cand_names = c("a", "b", "c"), skip_non_pivot_events = T, merge_adjacent_pivot_events = T)

plurality_out_sm <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F, skip_non_pivot_events = T, merge_adjacent_pivot_events = T)

borda_out_sm <- event_probabilities_from_event_list(event_list = borda_events, alpha = alpha6, cand_names = c("a", "b", "c"), ordinal = T, skip_non_pivot_events = T, merge_adjacent_pivot_events = T)
```


```{r try_it_drop_skip, cache = T}
# change it
irv_out_ds <- event_probabilities_from_event_list(event_list = irv_events, alpha = alpha6, cand_names = c("a", "b", "c"), drop_dimension = T, skip_non_pivot_events = T)

plurality_out_ds <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F, drop_dimension = T, skip_non_pivot_events = T)

borda_out_ds <- event_probabilities_from_event_list(event_list = borda_events, alpha = alpha6, cand_names = c("a", "b", "c"), ordinal = T, drop_dimension = T, skip_non_pivot_events = T)
```

```{r try_it_drop_skip_merge, cache = T}
# change
irv_out_dsm <- event_probabilities_from_event_list(event_list = irv_events, alpha = alpha6, cand_names = c("a", "b", "c"), drop_dimension = T, skip_non_pivot_events = T, merge_adjacent_pivot_events = T)

plurality_out_dsm <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F, drop_dimension = T, skip_non_pivot_events = T, merge_adjacent_pivot_events = T)

borda_out_dsm <- event_probabilities_from_event_list(event_list = borda_events, alpha = alpha6, cand_names = c("a", "b", "c"), ordinal = T, drop_dimension = T, skip_non_pivot_events = T, merge_adjacent_pivot_events = T)
```

```{r check_time}

tibble(system = c(rep("plurality4", 5), rep("irv", 5), rep("borda", 5)),
       type = rep(c("plain", "skip", "skipmerge", "dropskip", "dropskipmerge"), 3),
       time = c(plurality_out$total$seconds_elapsed,
                plurality_out_s$total$seconds_elapsed,
                plurality_out_sm$total$seconds_elapsed,
                plurality_out_ds$total$seconds_elapsed,
                plurality_out_dsm$total$seconds_elapsed,
                irv_out$total$seconds_elapsed,
                irv_out_s$total$seconds_elapsed,
                irv_out_sm$total$seconds_elapsed,
                irv_out_ds$total$seconds_elapsed,
                irv_out_dsm$total$seconds_elapsed,
                borda_out$total$seconds_elapsed,
                borda_out_s$total$seconds_elapsed,
                borda_out_sm$total$seconds_elapsed,
                borda_out_ds$total$seconds_elapsed,
                borda_out_dsm$total$seconds_elapsed)) %>% 
  pivot_wider(names_from = type, values_from = time) %>% 
  knitr::kable() 
```

Let's also look at the results! 


```{r look_at_results}
show_results <- function(base_name = "borda_out"){
  out <- get(base_name)
  out_s <- get(paste0(base_name, "_s"))
  out_sm <- get(paste0(base_name, "_sm"))
  out_ds <- get(paste0(base_name, "_ds"))
  out_dsm <- get(paste0(base_name, "_dsm"))
  tibble(pp = names(out), 
         base = map(out, "integral")) %>% 
    left_join(tibble(pp = names(out_s), 
                     skip = map(out_s, "integral")), by = "pp") %>% 
    left_join(tibble(pp = names(out_sm), 
                     skipmerge = map(out_sm, "integral")), by = "pp") %>%
    left_join(tibble(pp = names(out_ds), 
                     dropskip = map(out_ds, "integral")), by = "pp") %>%
    left_join(tibble(pp = names(out_dsm), 
                     dropskipmerge = map(out_dsm, "integral")), by = "pp") %>%
        knitr::kable()
}
```

```{r look_at_it_really}
show_results("plurality_out") # perfect. 

show_results("borda_out") # fine, although my scaling factor is off again sqrt(3) too large when dropping a dimension! will have to investigate again. 

show_results("irv_out") # this is completely fucked up. 
# on base, we get an NA on a_b|ab and similar (but not a_b|cb and similar). consistent with: an error in the event_list. but then when we drop a dimension we *do* get something there. 
# very confusing that base is fine except for a_b|ab and dropskipmerge is fine for everything. suggests an error with specification of a_b|ab that doesn't matter once we drop a dimension.
# very confusing that in conjunction with this skipmerge is all NAs.  


```

```{r look_at_it_raw_dawg}
irv_out
irv_out_sm
```
