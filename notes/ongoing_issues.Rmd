---
title: "Open questions and next steps"
author: "Andy Eggers"
date: "9/4/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
devtools::load_all()
# source("R/positional_utils.R") # for ordered ballot vector thing
# source("R/simplicial_cubature_utils.R") # for S creation
```

## Errors from Qhull in positional methods 

When I try to compute probabilities for a positional race with 4 candidates, I get a big long error referred to as the `dupridge` error in the qhull documentation. This is very annoying because it's possible that I have set up an elegant and flexible way to compute pivot probabilities for $k$-candidate positional elections but because of problems with software beyond my control I cannot go beyond the simplest case.  

```
>   out3 <- positional_event_probabilities(alpha = sample(2:7, size = 24, replace = T), skip_non_pivot_events = T, merge_adjacent_pivot_events = T, tol = .1)
Error in geometry::delaunayn(all_vertices[, -ncol(all_vertices)]) :
  Received error code 5 from qhull. Qhull error:
QH6271 qhull precision error (qh_check_dupridge): wide merge (130 times wider) due to duplicate ridge with nearly coincident points (0.00056) between f60215 and f60206, merge dist 1.3e-10, while processing p366
- Ignore error with option 'Q12'
- To be fixed in a later version of Qhull
- A bounding box for the input sites may alleviate this error.
- Vertex distance 0.00056 is greater than 100 times maximum distance 1e-12
  Please report to bradb@shore.net with steps to reproduce and all output
ERRONEOUS FACET:
- f60215
    - flags: bottom upperDelaunay new seen mergehorizon dupridge mergeridge2
    - normal:    0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085 3.032e-13
    - offset: -0.2085144
    - vertices: p366(v32) p430(v31) p1271(v29) p2282(v28) p1849(v27) p3664(v26) p3866
In addition: Warning messages:
1: In positional_event_probabilities(alpha = sample(2:7, size = 24,  :
  No score_vector supplied. Assuming Borda count with 4 candidates.
2: In geometry::delaunayn(all_vertices[, -ncol(all_vertices)]) :

 Error in geometry::delaunayn(all_vertices[, -ncol(all_vertices)]) :
  Received error code 5 from qhull. Qhull error:
QH6271 qhull precision error (qh_check_dupridge): wide merge (130 times wider) due to duplicate ridge with nearly coincident points (0.00056) between f60215 and f60206, merge dist 1.3e-10, while processing p366
- Ignore error with option 'Q12'
- To be fixed in a later version of Qhull
- A bounding box for the input sites may alleviate this error.
- Vertex distance 0.00056 is greater than 100 times maximum distance 1e-12
  Please report to bradb@shore.net with steps to reproduce and all output
ERRONEOUS FACET:
- f60215
    - flags: bottom upperDelaunay new seen mergehorizon dupridge mergeridge2
    - normal:    0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085   0.2085 3.032e-13
    - offset: -0.2085144
    - vertices: p366(v32) p430(v31) p1271(v29) p2282(v28) p1849(v27) p3664(v26) p3866 
```

I added the `Q12` option to `geometry::delaunayn()` and `geometry::convhulln()` and ran it again. It seemed to hang.

The documentation on Qhull is at http://www.qhull.org/html/qh-impre.htm. 

It looks I could pursue this by 

- switching away from Qhull
- waiting until `geometry` updates to `Qhull2019` and trying experimental option `Q14`
- trying to reproduce the error on a finer grain and seeing if there is something I can do to anticipate and avoid it

For now I am just restricting positional methods to 3 candidates.

And I think I will restrict Kemeny to 3 candidates.  

## Correction for dropping a dimension in positional methods 

I initially got different results when I drop a dimension and do not drop a dimension in positional methods. In the three-candidate case (the only one I've been able to handle so far), I got the same result in plurality and positional with `score_vector` `c(1,0,0)` when I do not drop a dimension. Dropping a dimension gave me pivot probabilities a factor of $\sqrt{2}$ higher. I confirmed in further tests (in `positional_utils.R`) that the factor varies across levels of `s`. I determined what the function seemed to be and have applied this. I now have approximately the same answers from dropping a dimension and not dropping a dimension. If this correction is correct, then I suspect it's correct even as we go to higher-order pivot events, but it won't work for more candidates, as the scoring system can no longer be characterized in terms of a single parameter `s`. But I don't understand why this is the correct scaling, and if I did understand it I could maybe do the extension to more candidates. 

## The scaling factor 

The full integral is the correct probability of each pivot event. This gets the probability that the result is such that an additional $1/n$ on one ballot type could change the outcome in a given way. We do this via the `S_array_from_inequalities_and_conditions()` function. When it does not drop a dimension or merge adjacent events, it computes a pivot probability by replacing an inequality (e.g. $v_i - v_j > \frac{1}{n}$) by a near equality ($0 < v_i - v_j < \frac{1}{n}$). 

The other approach is to compute the integral at an equality (e.g. $v_i = v_j$) and then scale up by the width of the channel over which we would otherwise be integrating. One might imagine that this width is $\frac{1}{n}$, but in plurality it is actually $\frac{1}{\sqrt{2} n}$ because of the unit simplex constraint. To see this, note that two points at either side of the channel are $(\frac{1}{2}, \frac{1}{2}, 0)$ and $(\frac{1}{2} + \frac{1}{2n}, \frac{1}{2} - \frac{1}{2n}, 0)$: the distance between them is $\frac{1}{\sqrt{2}n}$. 

We have two ways to compute the integral at an equality. One is to identify the facets of the convex hull where the equality holds and integrate along those facets. The other way is to use simulation: we draw a large number of simulated elections, we measure the proportion of simulations where the equality nearly holds and the other conditions hold (call this $q_E(x)$) and we rescale based on the window width. For example, we measure the proportion of cases where $-\frac{x}{2} < v_i - v_j < \frac{x}{2}$ for some $x$ chosen to deal with a bias/variance trade-off; we then divide by the window width, which again you might think is $x$ but it's actually $\frac{x}{\sqrt{2}}$ by the same logic as above. So the approximate integral is $\frac{\sqrt{2} q_E(x)}{x}$ and the pivot probability is $\frac{ \sqrt{2} q_E(x)}{x \sqrt{2} n} = \frac{ q_E(x)}{x n}$.    

Works for plurality and positional methods. Next I need to get the scaling factor for IRV I suppose, at each $s$. Should follow from positional. 


```{r compare3_function}
compare3_results <- function(x, y, z){
  tibble(pp = names(x), 
         first = map(x, "integral")) %>%
    unnest(first) %>% 
    left_join(tibble(pp = names(y), 
                     second = map(y, "integral")) %>% unnest(second), by = "pp") %>%
    left_join(tibble(pp = names(z), 
                     third = map(z, "integral")) %>% unnest(third), by = "pp") %>% 
    filter(pp != "total") %>% 
    mutate(ratio21 = second/first, ratio31 = third/first) %>% 
    knitr::kable()
}
```

```{r ev_checks_3, cache = T}
# xxxx
el3 <- plurality_event_list(n = 1000, k = 3)
calc_3 <- el3 %>%  
  event_probabilities_from_event_list(alpha = c(10, 7, 5), tol = .2)

sim_3 <- el3 %>% 
  event_probabilities_from_event_list(method = "mc", 
                                      alpha = c(10, 7, 5), 
                                      num_sims = 1000000)

ev_3 <- el3 %>% event_probabilities_from_event_list(method = "ev", alpha = c(10, 7, 5))
```

```{r plurality_compare3_ev}
compare3_results(calc_3, sim_3, ev_3)
```



```{r plurality_calcs_3, cache = T}
# xx
el3 <- plurality_event_list(n = 1000, k = 3)
calc_3 <- event_probabilities_from_event_list(event_list = el3, alpha = c(10, 7, 5), cand_names = c("a", "b", "c"), tol = .01)
calc_3d <- event_probabilities_from_event_list(event_list = el3, alpha = c(10, 7, 5), cand_names = c("a", "b", "c"), drop_dimension = T, tol = .1)
sim_3 <- event_probabilities_from_event_list(event_list = el3, alpha = c(10, 7, 5), draw_sims = T, num_sims = 1000000, cand_names = c("a", "b", "c"))
```

```{r plurality_compare3}
compare3_results(calc_3, calc_3d, sim_3)
```


```{r plurality_calcs_4, cache = T}
#x  xx
el4 <- plurality_event_list(n = 1000, k = 4)
calc_4 <- event_probabilities_from_event_list(event_list = el4, alpha = c(10, 7, 5, 3), cand_names = c("a", "b", "c", "d"), tol = .1)
calc_4d <- event_probabilities_from_event_list(event_list = el4, alpha = c(10, 7, 5, 3), cand_names = c("a", "b", "c", "d"), drop_dimension = T, tol = .1)
sim_4 <- event_probabilities_from_event_list(event_list = el4, alpha = c(10, 7, 5, 3), draw_sims = T, num_sims = 1000000, cand_names = c("a", "b", "c", "d"))
```

```{r plurality_compare4}
compare3_results(calc_4, calc_4d, sim_4)
```



```{r plurality_calcs_6, cache = T}
#x  xx
el6 <- plurality_event_list(n = 1000, k = 6)
alpha6 <- c(13, 10, 7, 5, 3.1, 3)
calc_6 <- el6 %>% event_probabilities_from_event_list(alpha = alpha6, skip_non_pivot_events = T, merge_adjacent_pivot_events = T, skip_compound_pivot_events = T, tol = .2)
sim_6 <- el6 %>% event_probabilities_from_event_list(method = "mc", alpha = alpha6, num_sims = 1000000)
ev_6 <- el6 %>% event_probabilities_from_event_list(method = "ev", alpha = alpha6)
```

<!-- ```{r more_sims, cache = T} -->
<!-- sim_6a <- el6 %>% event_probabilities_from_event_list(method = "mc", alpha = alpha6, num_sims = 5000000) -->
<!-- ``` -->


```{r plurality_compare6}
compare3_results(calc_6, sim_6, ev_6)
```

```{r borda_calcs, cache = T}
#x xx
borda <- positional_event_list(n = 1000, s = .5)
alpha6 <- c(10, 4, 6,5, 3,9)
calc_bc <- event_probabilities_from_event_list(event_list = borda, alpha = alpha6, tol = .1)
calc_bcd <- event_probabilities_from_event_list(event_list = borda, alpha = alpha6, tol = .1,  drop_dimension = T)
sim_bc <- event_probabilities_from_event_list(event_list = borda, alpha = alpha6, draw_sims = T, tol = .1, num_sims = 1000000)
```

```{r borda_compare}
compare3_results(calc_bc, calc_bcd, sim_bc)
```

Looks good. 

Another positional method:

```{r pos2_calcs, cache = T}
#x xxx
pos2 <- positional_event_list(n = 1000, s = .2)
alpha6 <- c(10, 4, 6,5, 3,9)
calc_pos2 <- event_probabilities_from_event_list(event_list = pos2, alpha = alpha6, tol = .1)
calc_pos2d <- event_probabilities_from_event_list(event_list = pos2, alpha = alpha6, tol = .1,  drop_dimension = T)
sim_pos2 <- event_probabilities_from_event_list(event_list = pos2, alpha = alpha6, draw_sims = T, tol = .1, num_sims = 1000000)
```


```{r pos2_compare}
compare3_results(calc_pos2, calc_pos2d, sim_pos2)
```



```{r irv_calcs, cache = T}
#x xxx
irv <- irv_event_list(n = 1000, s = 0)
alpha6 <- c(10, 4, 6,5, 3,9)
calc_irv <- event_probabilities_from_event_list(event_list = irv, alpha = alpha6, tol = .2)
calc_irvd <- event_probabilities_from_event_list(event_list = irv, alpha = alpha6, tol = .2,  drop_dimension = T, merge_adjacent_pivot_events = T)
sim_irv <- event_probabilities_from_event_list(event_list = irv, alpha = alpha6, draw_sims = T, tol = .1, num_sims = 1000000)
```

```{r irv_compare}
compare3_results(calc_irv, calc_irvd, sim_irv)
```


```{r irv_calcs_en, cache = T}
#x xs
irv <- irv_event_list(n = 1000, s = 0)
alpha6 <- c(10, 4, 6,5, 3,9)
calc_en <- irv %>% event_probabilities_from_event_list(method = "en", alpha = alpha6)
```

```{r irv_compare_en}
compare3_results(calc_irv, sim_irv, calc_en)
```



```{r irv_calcs2, cache = T}
#x xxxx
irv2 <- irv_event_list(n = 1000, s = .5)
alpha6 <- c(10, 4, 6,5, 3,9)
calc_irv2 <- event_probabilities_from_event_list(event_list = irv2, alpha = alpha6, tol = .2)
calc_irvd2 <- event_probabilities_from_event_list(event_list = irv2, alpha = alpha6, tol = .2,  drop_dimension = T, merge_adjacent_pivot_events = T)
sim_irv2 <- event_probabilities_from_event_list(event_list = irv2, alpha = alpha6, draw_sims = T, tol = .1, num_sims = 1000000)
```


```{r irv2_compare}
compare3_results(calc_irv2, calc_irvd2, sim_irv2)
```




```{r kemeny_calcs2, cache = T}
#x xx
ky <- kemeny_young_event_list(n = 1000)
alpha6 <- c(10, 4, 6,5, 3,9)
calc_ky <- event_probabilities_from_event_list(event_list = ky, alpha = alpha6, tol = .2)
calc_kyd <- event_probabilities_from_event_list(event_list = ky, alpha = alpha6, tol = .2,  drop_dimension = T, merge_adjacent_pivot_events = T)
sim_ky <- event_probabilities_from_event_list(event_list = ky, alpha = alpha6, draw_sims = T, num_sims = 1000000)
```


```{r ky_compare}
compare3_results(calc_ky, calc_kyd, sim_ky)
```



## Cleaning up and generalizing code

I have undertaken a new approach that I think is really promising. Each event is a set of conditions, a vector of rows to alter, and a $P$ matrix at those conditions. Then we cycle through permutations of the candidates and compute each pivot event for each permutation. (The cycling works differently when it comes to parameters depending on whether it is a single-ballot or ordinal system.) 

Done: 
- define adjacent events in the spec and update code to do this: if we are merging adjacent pivot events, and if this one has one specified, then substitute ijk in the same way, check if that one is already stored, and if so take it out, stick it in, move on. 
- write a function to make plurality events given n and k
- make the scaling factor 1 by default, and only specify it otherwise
- make IRV function that takes n and s, with the first round being any positional method 
- add simulation method, also based on conditions. 
- check IRV function: via simulation, not getting any hits for i_j|ij and I can't see why not. 
- add Kemeny.
- work out scaling factors for simulation vs exact. 
- for each method, check the results with and without drop_dimension to get the correct scaling factor
- put ordinal flag in event_list. 
- clean up the way n is specified -- silly to have it in every method
- clean up scaling for simulation. Can think of this not as integral followed by expansion, but desired nominal width of 1/n and actual nominal width of x, so get (piw / x/(1/n)) = piw/nx. low priority. 
- put in Eggers Vivyan, check against "truth": show it is least correct for even race. 
- put in Eggers Nowacki, check: should be correct and MUCH faster. 
- check and fix P matrix in ordinal methods: priority I guess. 
- investigate testing frameworks and implement 


To do on this: 

- check also that, when integral should be higher this side of the boundary, we get about the same result for merge_adjacent_pivot_events whether or not we drop_dimension, and the one on this side of the boundary is higher when we do not  merge_adjacent_pivot_events
- decide how to store the events as part of the package -- that's data. 
- why NaNs produced in log()
- consider allowing distinct adjacent pivot events with Eggers-Vivyan 
- document and clean up code 
- further testing.  

Here's some testing of it:

```{r compare_function}
compare_results <- function(x, y){
  tibble(pp = names(x), 
         first = map(x, "integral")) %>%
    unnest(first) %>% 
    left_join(tibble(pp = names(y), 
                     second = map(y, "integral")) %>% unnest(second), by = "pp") %>%
    filter(pp != "total") %>% 
    mutate(ratio = second/first) %>% 
    knitr::kable()
}
```

```{r check_simulation_approach, cache = T}
# xxxx
el <- plurality_event_list(n = 1000, k = 4)
sim_4 <- event_probabilities_from_event_list(event_list = el, ordinal = F, alpha = c(10, 7, 5, 4), draw_sims = T, num_sims = 2000000, cand_names = c("a", "b", "c", "d"))
```

```{r analytical_exact, cache = T}
# 
calc_4 <- event_probabilities_from_event_list(event_list = el, ordinal = F, alpha = c(10, 7, 5, 4), cand_names = c("a", "b", "c", "d"), tol = .001)
```

```{r compare_it}
compare_results(calc_4, sim_4)
```




```{r check_simulation_approach_borda, cache = T}
# xxxx
borda <- positional_event_list(n = 1000, s = .5)
sim_borda <- event_probabilities_from_event_list(event_list = borda, alpha = c(10, 2, 5, 4, 3, 7), draw_sims = T, num_sims = 2000000, cand_names = c("a", "b", "c"))
```

```{r borda_analytical, cache = T}
# 
calc_borda <- event_probabilities_from_event_list(event_list = borda,  alpha = c(10, 2, 5, 4, 3, 7), cand_names = c("a", "b", "c"), tol = .1, merge_adjacent_pivot_events = T)
```

```{r compare_it_fuckr}
compare_results(calc_borda, sim_borda)
```


```{r check_simulation_approach_irv, cache = T}
# xxxx
irv <- irv_event_list(n = 1000, s = 0)
sim_irv <- event_probabilities_from_event_list(event_list = irv, alpha = c(10, 2, 5, 4, 3, 7), draw_sims = T, num_sims = 2000000, cand_names = c("a", "b", "c"))
```

<!-- This has to await IRV fixing -- we have an event type whose conditions are never met.  -->
```{r irv_analytical, cache = T}
## 
calc_irv <- event_probabilities_from_event_list(event_list = irv,  alpha = c(10, 2, 5, 4, 3, 7), cand_names = c("a", "b", "c"), tol = .1, merge_adjacent_pivot_events = T)
```

```{r compare_it_fuckrdoodle}
compare_results(calc_irv, sim_irv)
```




```{r check_simulation_approach_irv_2, cache = T}
# xxxx
irv <- irv_event_list(n = 1000, s = .5)
sim_irv <- event_probabilities_from_event_list(event_list = irv, alpha = c(10, 2, 5, 4, 3, 7), draw_sims = T, num_sims = 2000000, cand_names = c("a", "b", "c"))
```

<!-- This has to await IRV fixing -- we have an event type whose conditions are never met.  -->
```{r irv_analytical_2, cache = T}
# cha
calc_irv <- event_probabilities_from_event_list(event_list = irv,  alpha = c(10, 2, 5, 4, 3, 7), cand_names = c("a", "b", "c"), tol = .1, merge_adjacent_pivot_events = T)
```

```{r compare_it_fuckrdoodle_2}
compare_results(calc_irv, sim_irv)
```


```{r get_events}
el <- plurality_event_list(n = 1000, k = 4)
irv_events <- irv_event_list(n = 1000)
borda_events <- positional_event_list(n = 1000)

alpha6 <- c(6,4, 3,4, 2,6)
alpha4 <- c(10, 9, 6, 4)
```

```{r try_it_basic, cache = T}
# change it X
irv_out <- event_probabilities_from_event_list(event_list = irv_events, alpha = alpha6, cand_names = c("a", "b", "c"), tol = .1)

plurality_out <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F, tol = .1)

borda_out <- event_probabilities_from_event_list(event_list = borda_events, alpha = alpha6, cand_names = c("a", "b", "c"), ordinal = T, tol = .1)
```


```{r try_it_skip, cache = T}
# change it X
irv_out_s <- event_probabilities_from_event_list(event_list = irv_events, alpha = alpha6, cand_names = c("a", "b", "c"), skip_non_pivot_events = T, tol = .1)

plurality_out_s <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F, skip_non_pivot_events = T, tol = .1)

borda_out_s <- event_probabilities_from_event_list(event_list = borda_events, alpha = alpha6, cand_names = c("a", "b", "c"), ordinal = T, skip_non_pivot_events = T, tol = .1)
```

```{r try_it_skip_merge, cache = T}
# change X
irv_out_sm <- event_probabilities_from_event_list(event_list = irv_events, alpha = alpha6, cand_names = c("a", "b", "c"), skip_non_pivot_events = T, merge_adjacent_pivot_events = T, tol = .1)

plurality_out_sm <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F, skip_non_pivot_events = T, merge_adjacent_pivot_events = T, tol = .1)

borda_out_sm <- event_probabilities_from_event_list(event_list = borda_events, alpha = alpha6, cand_names = c("a", "b", "c"), ordinal = T, skip_non_pivot_events = T, merge_adjacent_pivot_events = T, tol = .1)
```


```{r try_it_drop_skip, cache = T}
# change it X
irv_out_ds <- event_probabilities_from_event_list(event_list = irv_events, alpha = alpha6, cand_names = c("a", "b", "c"), drop_dimension = T, skip_non_pivot_events = T, tol = .1)

plurality_out_ds <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F, drop_dimension = T, skip_non_pivot_events = T, tol = .1)

borda_out_ds <- event_probabilities_from_event_list(event_list = borda_events, alpha = alpha6, cand_names = c("a", "b", "c"), ordinal = T, drop_dimension = T, skip_non_pivot_events = T, tol = .1)
```


```{r and_again, cache = T}
plurality_out_ds <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F, skip_non_pivot_events = T, drop_dimension = T, tol = .1)
```


```{r try_it_drop_skip_merge, cache = T}
# change X
irv_out_dsm <- event_probabilities_from_event_list(event_list = irv_events, alpha = alpha6, cand_names = c("a", "b", "c"), drop_dimension = T, skip_non_pivot_events = T, merge_adjacent_pivot_events = T, tol = .1)

plurality_out_dsm <- event_probabilities_from_event_list(event_list = el, alpha = alpha4, cand_names = c("a", "b", "c", "d"), ordinal = F, drop_dimension = T, skip_non_pivot_events = T, merge_adjacent_pivot_events = T, tol = .1)

borda_out_dsm <- event_probabilities_from_event_list(event_list = borda_events, alpha = alpha6, cand_names = c("a", "b", "c"), ordinal = T, drop_dimension = T, skip_non_pivot_events = T, merge_adjacent_pivot_events = T, tol = .1)
```

```{r check_time}

tibble(system = c(rep("plurality4", 5), rep("irv", 5), rep("borda", 5)),
       type = rep(c("plain", "skip", "skipmerge", "dropskip", "dropskipmerge"), 3),
       time = c(plurality_out$total$seconds_elapsed,
                plurality_out_s$total$seconds_elapsed,
                plurality_out_sm$total$seconds_elapsed,
                plurality_out_ds$total$seconds_elapsed,
                plurality_out_dsm$total$seconds_elapsed,
                irv_out$total$seconds_elapsed,
                irv_out_s$total$seconds_elapsed,
                irv_out_sm$total$seconds_elapsed,
                irv_out_ds$total$seconds_elapsed,
                irv_out_dsm$total$seconds_elapsed,
                borda_out$total$seconds_elapsed,
                borda_out_s$total$seconds_elapsed,
                borda_out_sm$total$seconds_elapsed,
                borda_out_ds$total$seconds_elapsed,
                borda_out_dsm$total$seconds_elapsed)) %>% 
  pivot_wider(names_from = type, values_from = time) %>% 
  knitr::kable() 
```

Let's also look at the results! 


```{r look_at_results}
show_results <- function(base_name = "borda_out"){
  out <- get(base_name)
  out_s <- get(paste0(base_name, "_s"))
  out_sm <- get(paste0(base_name, "_sm"))
  out_ds <- get(paste0(base_name, "_ds"))
  out_dsm <- get(paste0(base_name, "_dsm"))
  tibble(pp = names(out), 
         base = map(out, "integral")) %>% 
    left_join(tibble(pp = names(out_s), 
                     skip = map(out_s, "integral")), by = "pp") %>% 
    left_join(tibble(pp = names(out_sm), 
                     skipmerge = map(out_sm, "integral")), by = "pp") %>%
    left_join(tibble(pp = names(out_ds), 
                     dropskip = map(out_ds, "integral")), by = "pp") %>%
    left_join(tibble(pp = names(out_dsm), 
                     dropskipmerge = map(out_dsm, "integral")), by = "pp") %>%
        knitr::kable()
}
```

```{r look_at_it_really}
show_results("plurality_out") # perfect. 

show_results("borda_out") # fine, although my scaling factor is off again sqrt(3) too large when dropping a dimension! will have to investigate again. 

show_results("irv_out") # this is completely fucked up. 
# on base, we get an NA on a_b|ab and similar (but not a_b|cb and similar). consistent with: an error in the event_list. but then when we drop a dimension we *do* get something there. 
# very confusing that base is fine except for a_b|ab and dropskipmerge is fine for everything. suggests an error with specification of a_b|ab that doesn't matter once we drop a dimension.
# very confusing that in conjunction with this skipmerge is all NAs.  


```

Checking plurality scaling factors. 

```{r plurality_calcs, cache = T}
# x
plurality_3 <- event_probabilities_from_event_list(event_list = plurality_event_list(k = 3), alpha = c(10, 8, 4), cand_names = c("a", "b", "c"), ordinal = F, tol = .1, skip_non_pivot_events = T)
plurality_3_drop <- event_probabilities_from_event_list(event_list = plurality_event_list(k = 3), alpha = c(10, 8, 4), cand_names = c("a", "b", "c"), ordinal = F, tol = .1, skip_non_pivot_events = T, drop_dimension = T)
```

```{r check_it_fucker}
n <- 1000

el <- plurality_event_list(k = 4, n = n)
S_array_from_inequalities_and_conditions(el[["i_jk"]]$conditions, rows_to_alter = c(1,2), limits = c(0, 1/n)) # this works 
S_array_from_inequalities_and_conditions(el[["i_jk"]]$conditions, rows_to_alter = c(1,2), limits = c(0, 0), drop_dimension = T) # This works. There are no whole simplices where the conditions are met, but we have two vertices where they meet and we stick them together.  


el <- plurality_event_list(k = 5, n = n)
S_array_from_inequalities_and_conditions(el[["i_jk"]]$conditions, rows_to_alter = c(1,2), limits = c(0, 1/n)) # this works 
S_array_from_inequalities_and_conditions(el[["i_jk"]]$conditions, rows_to_alter = c(1,2), limits = c(0, 0), drop_dimension = T) # Initially had an error -- was not finding any simplices to integrate over. 

```

```{r how_about_5, cache = T}
# x
plurality_5 <- event_probabilities_from_event_list(event_list = plurality_event_list(k = 5), alpha = c(10, 8, 6,  4, 2), cand_names = c("a", "b", "c", "d", "e"), ordinal = F, tol = .1, skip_non_pivot_events = T)
plurality_5_drop <- event_probabilities_from_event_list(event_list = plurality_event_list(k = 5), alpha = c(10, 8, 6, 4, 2), cand_names = c("a", "b", "c", "d", "e"), ordinal = F, tol = .1, skip_non_pivot_events = T, drop_dimension = T)
```

```{r how_about_6, cache = T}
# x
plurality_6 <- event_probabilities_from_event_list(event_list = plurality_event_list(k = 6), alpha = c(13, 10, 8, 6,  4, 2), cand_names = c("a", "b", "c", "d", "e", "f"), ordinal = F, tol = .1, skip_non_pivot_events = T)
plurality_6_drop <- event_probabilities_from_event_list(event_list = plurality_event_list(k = 6), alpha = c(13, 10, 8, 6, 4, 2), cand_names = c("a", "b", "c", "d", "e", "f"), ordinal = F, tol = .1, skip_non_pivot_events = T, drop_dimension =T)
```



```{r plurality_checks}
compare_results(plurality_3, plurality_3_drop)
compare_results(plurality_out_s, plurality_out_ds)
compare_results(plurality_5, plurality_5_drop)
```

```{r look_at_it_raw_dawg}
irv_out
irv_out_sm
```
